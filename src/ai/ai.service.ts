import { Injectable } from '@nestjs/common';
import OpenAI from 'openai';

@Injectable()
export class AiService {
  private readonly openai = new OpenAI({
    baseURL: 'https://openrouter.ai/api/v1',
    apiKey: process.env.DEEPSEEK_API_KEY ?? '',
  });

  private readonly model = 'deepseek/deepseek-r1:free';

  private throttle = false;

  async generate(prompt: string, systemMessage?: string, temperature?: number) {
    if (this.throttle) {
      return 'ðŸ ÐšÐ¾Ð·Ð° Ð´ÑƒÐ¼Ð°ÐµÑ‚, Ð´Ð¾Ð¶Ð´Ð¸ÑÑŒ Ð¾Ñ‚Ð²ÐµÑ‚Ð°';
    }

    systemMessage =
      systemMessage?.trim() ?? 'Ð¢Ñ‹ Ð³Ð½Ð¾Ð¼Ð¸Ðº, ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð³Ð¾ Ð·Ð°Ð¿ÐµÑ€Ð»Ð¸ Ð² ÐºÐ¾Ð¼Ð¿ÑŒÑŽÑ‚ÐµÑ€Ðµ';
    temperature = temperature ?? 1;

    this.throttle = true;

    return this.openai.chat.completions
      .create({
        model: this.model,
        messages: [
          { role: 'user', content: prompt },
          {
            role: 'system',
            content: systemMessage,
          },
        ],
        temperature: temperature,
      })
      .then((response) => {
        return response.choices[0].message.content;
      })
      .finally(() => {
        this.throttle = false;
      });
  }
}
